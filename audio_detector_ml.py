"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë              –î–µ—Ç–µ–∫—Ç–æ—Ä –∑–≤—É–∫–∞ –æ—Ç–∫—Ä—ã—Ç–∏—è –±–∞–Ω–∫–∏ –ø–∏–≤–∞ üç∫ (ML –≤–µ—Ä—Å–∏—è)               ‚ïë
‚ïë                                                                              ‚ïë
‚ïë  –ò—Å–ø–æ–ª—å–∑—É–µ—Ç Machine Learning –¥–ª—è –≤—ã—Å–æ–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è.             ‚ïë
‚ïë  –û–±—É—á–µ–Ω –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –∑–∞–ø–∏—Å—è—Ö –æ—Ç–∫—Ä—ã—Ç–∏—è –±–∞–Ω–æ–∫ + —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –Ω–µ–≥–∞—Ç–∏–≤–∞—Ö.       ‚ïë
‚ïë                                                                              ‚ïë
‚ïë  –¢–æ—á–Ω–æ—Å—Ç—å: ~95% –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö                                          ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
"""

import numpy as np
import pyaudio
import time
import os
import sys
import pickle
from collections import deque
from scipy import signal

from config import AUDIO_SETTINGS, DETECTOR_SETTINGS


def get_resource_path(filename):
    """–ü–æ–ª—É—á–∏—Ç—å –ø—É—Ç—å –∫ —Ä–µ—Å—É—Ä—Å—É (—Ä–∞–±–æ—Ç–∞–µ—Ç –∏ –≤ .py, –∏ –≤ .exe)"""
    if getattr(sys, 'frozen', False):
        # –ó–∞–ø—É—â–µ–Ω –∫–∞–∫ .exe (PyInstaller)
        base_path = sys._MEIPASS
    else:
        # –ó–∞–ø—É—â–µ–Ω –∫–∞–∫ .py
        base_path = os.path.dirname(__file__)
    return os.path.join(base_path, filename)


# –ü—É—Ç—å –∫ ML –º–æ–¥–µ–ª–∏
MODEL_PATH = get_resource_path("beer_detector_model.pkl")

# –ü—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è ML –º–æ–¥–µ–ª–∏ (–¥–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å train_model.py)
FEATURE_NAMES = [
    'duration_ms',
    'rms',
    'peak',
    'zcr',
    'spectral_centroid',
    'spectral_rolloff',
    'energy_0_500',
    'energy_500_2000',
    'energy_2000_5000',
    'energy_5000_10000',
    'energy_10000_20000',
    'high_low_ratio',
    'attack_ratio',
    'decay_50_ratio',
    'spectral_flux'
]


class BeerCanDetector:
    """
    ML-–¥–µ—Ç–µ–∫—Ç–æ—Ä –∑–≤—É–∫–∞ –æ—Ç–∫—Ä—ã—Ç–∏—è –±–∞–Ω–∫–∏ –ø–∏–≤–∞.
    
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å RandomForest –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∑–≤—É–∫–æ–≤.
    –ì–æ—Ä–∞–∑–¥–æ —Ç–æ—á–Ω–µ–µ –ø—Ä–æ—Å—Ç–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å —ç—Ç–∞–ª–æ–Ω–∞–º–∏!
    """
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ —Å ML –º–æ–¥–µ–ª—å—é."""
        # PyAudio –¥–ª—è –∑–∞–ø–∏—Å–∏
        self.audio = pyaudio.PyAudio()
        self.stream = None
        self.is_running = False
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∞—É–¥–∏–æ
        self.rate = AUDIO_SETTINGS["rate"]
        self.chunk = AUDIO_SETTINGS["chunk"]
        self.channels = AUDIO_SETTINGS["channels"]
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞
        self.peak_threshold = DETECTOR_SETTINGS["peak_threshold"]
        self.cooldown = DETECTOR_SETTINGS["cooldown"]
        self.debug_mode = DETECTOR_SETTINGS.get("debug_mode", False)
        
        # ML –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (–≤—ã—à–µ = –º–µ–Ω—å—à–µ –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π)
        self.ml_threshold = 0.7  # 70% —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º ML –º–æ–¥–µ–ª—å
        self.model = None
        self.scaler = None
        self._load_model()
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ
        self.last_trigger_time = 0
        self.last_debug_time = 0
        
        # –ë—É—Ñ–µ—Ä –∞—É–¥–∏–æ (800–º—Å –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –ø–æ–ª–Ω–æ–≥–æ –∑–≤—É–∫–∞)
        self.audio_buffer = deque(maxlen=int(self.rate * 0.8))
        
        # –§–æ–Ω–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å
        self.background_levels = deque(maxlen=30)
        self.background_level = 0.01
        
        # –°—á—ë—Ç—á–∏–∫ –¥–ª—è –ø–æ–¥–∞–≤–ª–µ–Ω–∏—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π
        self.consecutive_detections = 0
    
    def _load_model(self):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –æ–±—É—á–µ–Ω–Ω—É—é ML –º–æ–¥–µ–ª—å."""
        if os.path.exists(MODEL_PATH):
            try:
                with open(MODEL_PATH, 'rb') as f:
                    data = pickle.load(f)
                self.model = data['model']
                self.scaler = data['scaler']
                print(f"   ü§ñ ML –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {MODEL_PATH}")
            except Exception as e:
                print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
                self.model = None
        else:
            print(f"   ‚ö†Ô∏è ML –º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {MODEL_PATH}")
            print("   –ó–∞–ø—É—Å—Ç–∏—Ç–µ: python train_model.py")
    
    def _extract_ml_features(self, segment: np.ndarray) -> dict:
        """
        –ò–∑–≤–ª–µ—á—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è ML –º–æ–¥–µ–ª–∏.
        
        –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
            segment: numpy –º–∞—Å—Å–∏–≤ —Å –∞—É–¥–∏–æ –¥–∞–Ω–Ω—ã–º–∏ (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π -1..1)
        
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            dict —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –¥–ª—è –º–æ–¥–µ–ª–∏
        """
        features = {}
        sr = self.rate
        
        # 1. –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        features['duration_ms'] = len(segment) / sr * 1000
        
        # 2. RMS (–≥—Ä–æ–º–∫–æ—Å—Ç—å)
        features['rms'] = float(np.sqrt(np.mean(segment**2)))
        
        # 3. Peak
        features['peak'] = float(np.max(np.abs(segment)))
        
        # 4. Zero Crossing Rate
        zcr = np.sum(np.abs(np.diff(np.sign(segment)))) / (2 * len(segment))
        features['zcr'] = float(zcr)
        
        # 5. –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
        nperseg = min(1024, len(segment) // 2)
        if nperseg < 64:
            nperseg = 64
        
        try:
            f, Pxx = signal.welch(segment, sr, nperseg=nperseg)
        except:
            # Fallback
            f = np.linspace(0, sr/2, 100)
            Pxx = np.ones(100) * 0.001
        
        # –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π —Ü–µ–Ω—Ç—Ä–æ–∏–¥
        total_power = np.sum(Pxx) + 1e-10
        centroid = np.sum(f * Pxx) / total_power
        features['spectral_centroid'] = float(centroid)
        
        # –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π rolloff (95% —ç–Ω–µ—Ä–≥–∏–∏)
        cumsum = np.cumsum(Pxx)
        rolloff_idx = np.searchsorted(cumsum, 0.95 * cumsum[-1])
        features['spectral_rolloff'] = float(f[min(rolloff_idx, len(f)-1)])
        
        # 6. –≠–Ω–µ—Ä–≥–∏—è –ø–æ –ø–æ–ª–æ—Å–∞–º —á–∞—Å—Ç–æ—Ç
        bands = [(0, 500), (500, 2000), (2000, 5000), (5000, 10000), (10000, 20000)]
        for low, high in bands:
            mask = (f >= low) & (f < high)
            band_energy = np.sum(Pxx[mask])
            features[f'energy_{low}_{high}'] = float(band_energy / total_power)
        
        # 7. –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –≤—ã—Å–æ–∫–∏—Ö –∫ –Ω–∏–∑–∫–∏–º —á–∞—Å—Ç–æ—Ç–∞–º
        low_mask = f < 2000
        high_mask = (f >= 2000) & (f < 8000)
        low_energy = np.sum(Pxx[low_mask]) + 1e-10
        high_energy = np.sum(Pxx[high_mask])
        features['high_low_ratio'] = float(high_energy / low_energy)
        
        # 8. Attack time
        peak_idx = np.argmax(np.abs(segment))
        features['attack_ratio'] = float(peak_idx / len(segment))
        
        # 9. Decay time
        after_peak = np.abs(segment[peak_idx:])
        if len(after_peak) > 10:
            window = min(50, len(after_peak) // 2)
            if window > 0:
                decay_envelope = np.convolve(after_peak, np.ones(window)/window, mode='valid')
                if len(decay_envelope) > 0:
                    half_idx = np.searchsorted(-decay_envelope, -decay_envelope[0] * 0.5)
                    features['decay_50_ratio'] = float(min(half_idx / len(after_peak), 1.0))
                else:
                    features['decay_50_ratio'] = 0.5
            else:
                features['decay_50_ratio'] = 0.5
        else:
            features['decay_50_ratio'] = 0.5
        
        # 10. –°–ø–µ–∫—Ç—Ä–∞–ª—å–Ω—ã–π flux
        n_frames = max(1, len(segment) // 512)
        if n_frames > 1:
            frame_size = len(segment) // n_frames
            spectra = []
            for i in range(n_frames):
                frame = segment[i*frame_size:(i+1)*frame_size]
                if len(frame) > 0:
                    spec = np.abs(np.fft.rfft(frame))
                    spec = spec / (np.max(spec) + 1e-10)
                    spectra.append(spec[:min(len(spec), 256)])
            
            if len(spectra) > 1:
                max_len = max(len(s) for s in spectra)
                spectra = [np.pad(s, (0, max_len - len(s))) for s in spectra]
                spectra = np.array(spectra)
                flux = np.mean(np.sqrt(np.sum(np.diff(spectra, axis=0)**2, axis=1)))
                features['spectral_flux'] = float(flux)
            else:
                features['spectral_flux'] = 0.0
        else:
            features['spectral_flux'] = 0.0
        
        return features
    
    def _find_sound_segment(self, audio_data: np.ndarray) -> np.ndarray:
        """–ù–∞–π—Ç–∏ –≥—Ä–∞–Ω–∏—Ü—ã –∑–≤—É–∫–∞ –≤ –±—É—Ñ–µ—Ä–µ."""
        envelope = np.abs(audio_data)
        
        window = int(self.rate * 0.005)
        if window > 0:
            envelope = np.convolve(envelope, np.ones(window)/window, mode='same')
        
        peak_val = np.max(envelope)
        threshold = peak_val * 0.05
        
        above_threshold = np.where(envelope > threshold)[0]
        
        if len(above_threshold) < 50:
            peak_idx = np.argmax(np.abs(audio_data))
            samples_before = int(self.rate * 0.05)
            samples_after = int(self.rate * 0.3)
            start = max(0, peak_idx - samples_before)
            end = min(len(audio_data), peak_idx + samples_after)
            return audio_data[start:end]
        
        start_idx = above_threshold[0]
        end_idx = above_threshold[-1]
        
        # Padding
        padding = int(self.rate * 0.02)
        start_idx = max(0, start_idx - padding)
        end_idx = min(len(audio_data), end_idx + padding)
        
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞ (50-700–º—Å)
        min_samples = int(self.rate * 0.05)
        max_samples = int(self.rate * 0.7)
        
        segment_len = end_idx - start_idx
        
        if segment_len < min_samples:
            center = (start_idx + end_idx) // 2
            start_idx = max(0, center - min_samples // 2)
            end_idx = min(len(audio_data), start_idx + min_samples)
        elif segment_len > max_samples:
            peak_idx = start_idx + np.argmax(np.abs(audio_data[start_idx:end_idx]))
            start_idx = max(0, peak_idx - max_samples // 3)
            end_idx = min(len(audio_data), start_idx + max_samples)
        
        return audio_data[start_idx:end_idx]
    
    def _predict_with_ml(self, segment: np.ndarray) -> tuple:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å —Å –ø–æ–º–æ—â—å—é ML –º–æ–¥–µ–ª–∏.
        
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            tuple (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å_–ø–∏–≤–∞, –ø—Ä–∏–∑–Ω–∞–∫–∏)
        """
        if self.model is None or self.scaler is None:
            return 0.0, {}
        
        features = self._extract_ml_features(segment)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –≤–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        X = [[features.get(fn, 0.0) for fn in FEATURE_NAMES]]
        X = np.array(X)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
        try:
            X_scaled = self.scaler.transform(X)
            prob = self.model.predict_proba(X_scaled)[0, 1]
        except Exception as e:
            if self.debug_mode:
                print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ ML: {e}")
            return 0.0, features
        
        return float(prob), features
    
    def start_stream(self):
        """–ó–∞–ø—É—Å—Ç–∏—Ç—å –∑–∞–ø–∏—Å—å —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞."""
        self.stream = self.audio.open(
            format=pyaudio.paInt16,
            channels=self.channels,
            rate=self.rate,
            input=True,
            frames_per_buffer=self.chunk
        )
        self.is_running = True
        if self.model:
            print("üé§ –ú–∏–∫—Ä–æ—Ñ–æ–Ω –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω (ML –¥–µ—Ç–µ–∫—Ç–æ—Ä). –ò—â—É –∑–≤—É–∫ –æ—Ç–∫—Ä—ã—Ç–∏—è –±–∞–Ω–∫–∏...")
        else:
            print("üé§ –ú–∏–∫—Ä–æ—Ñ–æ–Ω –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω (–±–µ–∑ ML). –ó–∞–ø—É—Å—Ç–∏—Ç–µ train_model.py –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.")
    
    def stop_stream(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å."""
        self.is_running = False
        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
        self.audio.terminate()
        print("üîá –ú–∏–∫—Ä–æ—Ñ–æ–Ω –æ—Ç–∫–ª—é—á–µ–Ω.")
    
    def read_audio_chunk(self) -> np.ndarray:
        """–ü—Ä–æ—á–∏—Ç–∞—Ç—å –ø–æ—Ä—Ü–∏—é –∞—É–¥–∏–æ."""
        try:
            data = self.stream.read(self.chunk, exception_on_overflow=False)
            return np.frombuffer(data, dtype=np.int16)
        except Exception as e:
            return np.zeros(self.chunk, dtype=np.int16)
    
    def detect(self) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, –±—ã–ª –ª–∏ –∑–≤—É–∫ –æ—Ç–∫—Ä—ã—Ç–∏—è –±–∞–Ω–∫–∏.
        
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç ML –º–æ–¥–µ–ª—å –¥–ª—è –≤—ã—Å–æ–∫–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏.
        """
        current_time = time.time()
        
        # Cooldown
        if current_time - self.last_trigger_time < self.cooldown:
            return False
        
        # –ß–∏—Ç–∞–µ–º –∞—É–¥–∏–æ
        audio_data = self.read_audio_chunk()
        audio_normalized = audio_data / 32768.0
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –±—É—Ñ–µ—Ä
        self.audio_buffer.extend(audio_normalized)
        
        # –í—ã—á–∏—Å–ª—è–µ–º —É—Ä–æ–≤–Ω–∏
        rms = np.sqrt(np.mean(audio_normalized ** 2))
        peak = np.max(np.abs(audio_normalized))
        
        # –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Ñ–æ–Ω
        if rms < 0.02:
            self.background_levels.append(rms)
            if len(self.background_levels) > 5:
                self.background_level = np.mean(self.background_levels)
        
        # Debug –≤—ã–≤–æ–¥
        if self.debug_mode and current_time - self.last_debug_time >= 0.5:
            self.last_debug_time = current_time
            bar_length = int(rms * 200)
            bar = "‚ñà" * min(bar_length, 50) + "‚ñë" * (50 - min(bar_length, 50))
            status = "üîä" if peak > self.peak_threshold else "üîà"
            ml_status = "ü§ñ" if self.model else "‚ùå"
            print(f"{status}{ml_status} [{bar}] RMS:{rms:.3f} Peak:{peak:.3f}", end="\r")
        
        # –ê–Ω–∞–ª–∏–∑ –≥—Ä–æ–º–∫–∏—Ö –∑–≤—É–∫–æ–≤
        if peak > self.peak_threshold:
            
            buffer_array = np.array(self.audio_buffer)
            
            if len(buffer_array) < 1000:
                return False
            
            segment = self._find_sound_segment(buffer_array)
            
            if len(segment) > 500:
                
                # ML –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                prob, features = self._predict_with_ml(segment)
                
                if self.debug_mode:
                    hl_ratio = features.get('high_low_ratio', 0)
                    centroid = features.get('spectral_centroid', 0)
                    print(f"\n   ü§ñ ML –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {prob:.1%} | H/L: {hl_ratio:.1f} | Centroid: {centroid:.0f}Hz")
                
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π
                high_low_ratio = features.get('high_low_ratio', 0)
                spectral_centroid = features.get('spectral_centroid', 0)
                duration = features.get('duration_ms', 0)
                
                # –•–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–∏–≤–∞:
                # - –ú–Ω–æ–≥–æ –≤—ã—Å–æ–∫–∏—Ö —á–∞—Å—Ç–æ—Ç (high_low_ratio > 2)
                # - –¶–µ–Ω—Ç—Ä–æ–∏–¥ –≤—ã—à–µ 3000 Hz
                # - –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å 100-800 –º—Å
                is_hiss_like = high_low_ratio > 2.0
                is_high_freq = spectral_centroid > 3000
                is_valid_duration = 100 < duration < 800
                
                # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ
                if prob >= self.ml_threshold and is_hiss_like and is_high_freq and is_valid_duration:
                    print(f"\n\nüç∫ –ë–ê–ù–ö–ê –û–¢–ö–†–´–¢–ê! (ML: {prob:.1%}, H/L: {high_low_ratio:.1f})")
                    self.last_trigger_time = current_time
                    self.audio_buffer.clear()
                    self.consecutive_detections = 0
                    return True
                
                elif prob >= 0.5:
                    if self.debug_mode:
                        reasons = []
                        if not is_hiss_like:
                            reasons.append(f"H/L={high_low_ratio:.1f}<2")
                        if not is_high_freq:
                            reasons.append(f"centroid={spectral_centroid:.0f}<3000")
                        if not is_valid_duration:
                            reasons.append(f"dur={duration:.0f}ms")
                        print(f"   ‚ùå –ü–æ—Ö–æ–∂–µ, –Ω–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω–æ: {', '.join(reasons)}")
        
        return False
